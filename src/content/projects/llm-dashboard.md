---
title: 'LLM Performance Monitoring Dashboard'
description: Developed a real-time dashboard using NextJS, Recharts, FastAPI with WebSocket, and InfluxDB to monitor and aggregate GPU, VRAM, CPU, RAM utilization, and power consumption for running local inference using open-source LLMs.
publishDate: 'Jul 17 2024'
isFeatured: true
# seo:
#   image:
#     src: '/project-1.jpg'
#     alt: Project preview
---

<!-- ![Project preview](/project-1.jpg) -->

**Project Overview:**
Developed a real-time data visualization dashboard to monitor and aggregate GPU, VRAM, CPU, RAM utilization, and power consumption for running local inference using open-source LLMs.

## Objectives

1. Create a real-time dashboard to visualize and monitor system resource utilization during local inference.
2. Aggregate data from multiple sources to provide comprehensive insights into hardware performance.
3. Implement a scalable and efficient backend to support real-time data updates.

## Features

1. **Real-Time Data Visualization:**

   - Utilized NextJS and Recharts to create dynamic and responsive visualizations.
   - Monitored GPU, VRAM, CPU, RAM utilization, and power consumption in real-time.

2. **Efficient Data Aggregation:**

   - Employed FastAPI with WebSocket for seamless real-time data updates.
   - Aggregated hardware performance metrics using InfluxDB for efficient data storage and retrieval.

3. **Local Inference Monitoring:**

   - Designed specifically to monitor local inference tasks using open-source LLMs.
   - Provided detailed insights into resource utilization and power consumption.

## Tech Stack

- **Frontend:** NextJS, Recharts
- **Backend:** FastAPI, WebSocket
- **Database:** InfluxDB

## Outcome

The project resulted in a highly efficient and user-friendly dashboard for real-time monitoring of hardware performance during local inference, offering valuable insights into resource utilization and power consumption.
